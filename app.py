import streamlit as st
import pandas as pd
import re
import urllib.parse
from openai import OpenAI
import requests
import warnings
import httpx
import time
import io
import os
from bs4 import BeautifulSoup # ç”¨äºè§£æç½‘é¡µå†…å®¹

# å¿½ç•¥ SSL è­¦å‘Š
warnings.filterwarnings("ignore")

# ==========================================
# ğŸ”§ 988 Group äº‘ç«¯é…ç½®
# ==========================================
CONFIG = {
    "PROXY_URL": None, 
    "CN_BASE_URL": "https://api.checknumber.ai/wa/api/simple/tasks"
}

# 1. é¡µé¢é…ç½® (Page Config)
st.set_page_config(
    page_title="988 Group - Intelligent Supply Chain", 
    layout="wide", 
    page_icon="ğŸš›",
    initial_sidebar_state="expanded"
)

# 2. é«˜çº§æ„Ÿ CSS æ³¨å…¥ (Premium UI)
st.markdown("""
<style>
    /* å…¨å±€å­—ä½“ä¸èƒŒæ™¯ */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Inter', sans-serif;
    }
    
    /* éšè— Streamlit é»˜è®¤ç»„ä»¶ */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* ä¾§è¾¹æ æ ·å¼ */
    section[data-testid="stSidebar"] {
        background-color: #f4f6f9;
        border-right: 1px solid #e0e0e0;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    h1 {
        color: #003366; /* 988 æ·±è“ */
        font-weight: 700;
        letter-spacing: -1px;
    }
    
    /* æ ¸å¿ƒæŒ‰é’®ç¾åŒ– */
    div.stButton > button {
        background: linear-gradient(135deg, #004aad 0%, #003366 100%);
        color: white;
        border: none;
        padding: 0.6rem 1.2rem;
        border-radius: 8px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 6px rgba(0, 74, 173, 0.2);
        width: 100%;
    }
    div.stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0, 74, 173, 0.3);
    }
    
    /* ç»“æœå¡ç‰‡ (Glassmorphism) */
    div[data-testid="stExpander"] {
        background: white;
        border: 1px solid #edf2f7;
        border-radius: 12px;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05);
        margin-bottom: 12px;
        transition: box-shadow 0.2s;
    }
    div[data-testid="stExpander"]:hover {
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1);
        border-color: #cbd5e0;
    }
    
    /* çŠ¶æ€æç¤ºæ¡† */
    div[data-testid="stStatusWidget"] {
        border-radius: 10px;
        border: 1px solid #e2e8f0;
    }
</style>
""", unsafe_allow_html=True)

# === ä¾§è¾¹æ  ===
with st.sidebar:
    if os.path.exists("logo.png"):
        st.image("logo.png", width=180)
    else:
        st.markdown("## ğŸš› **988 Group**")
        
    st.markdown("---")
    st.markdown("### ğŸ“Š Control Panel")
    
    # å¯†é’¥è¯»å–
    try:
        default_cn_user = st.secrets["CN_USER_ID"]
        default_cn_key = st.secrets["CN_API_KEY"]
        default_openai = st.secrets["OPENAI_KEY"]
        is_configured = True
        st.caption("âœ… Cloud Secrets Loaded")
    except FileNotFoundError:
        default_cn_user = ""
        default_cn_key = ""
        default_openai = ""
        is_configured = False
        st.caption("âš ï¸ Local Mode")

    with st.expander("ğŸ”§ System Config"):
        use_proxy = st.checkbox("Enable Proxy (Local)", value=False)
        proxy_port = st.text_input("Proxy URL", value="http://127.0.0.1:10809")
        check_user_id = st.text_input("CN User ID", value=default_cn_user)
        check_key = st.text_input("CN Key", value=default_cn_key, type="password")
        openai_key = st.text_input("OpenAI Key", value=default_openai, type="password")

# === æ ¸å¿ƒåŠŸèƒ½æ¨¡å— ===

def get_proxy_config():
    if use_proxy and proxy_port: return proxy_port.strip()
    return None

def extract_web_content(url):
    """
    çˆ¬è™«æ¨¡å—ï¼šå°è¯•è·å–ç½‘é¡µæ ‡é¢˜å’Œæè¿°
    """
    if not url or not isinstance(url, str) or "http" not in url:
        return None
        
    # ä¼ªè£…æˆçœŸå®æµè§ˆå™¨
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7"
    }
    
    try:
        # è®¾ç½®çŸ­è¶…æ—¶ï¼Œé˜²æ­¢ Ozon å¡æ­»ç¨‹åº
        resp = requests.get(url, headers=headers, timeout=5)
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, 'html.parser')
            # è·å–æ ‡é¢˜
            title = soup.title.string.strip() if soup.title else ""
            # è·å–æè¿°
            desc = ""
            meta = soup.find('meta', attrs={'name': 'description'})
            if meta:
                desc = meta.get('content', '')
            
            return f"Page Title: {title} | Description: {desc[:200]}"
    except:
        return None # çˆ¬å–å¤±è´¥åˆ™è¿”å› Noneï¼Œåç»­ AI ä¼šè‡ªåŠ¨å›é€€åˆ° URL åˆ†æ
    return None

def extract_all_numbers(row_series):
    full_text = " ".join([str(val) for val in row_series if pd.notna(val)])
    # v20.0 æ­£åˆ™æå–é€»è¾‘
    matches_standard = re.findall(r'(\+?(?:7|8)(?:[\s\-\(\)]*\d){10})', full_text)
    matches_short = re.findall(r'(?:\D|^)(9(?:[\s\-\(\)]*\d){9})(?:\D|$)', full_text)
    all_raw_matches = matches_standard + matches_short
    
    candidates = []
    for raw in all_raw_matches:
        if isinstance(raw, tuple): raw = raw[0]
        digits = re.sub(r'\D', '', str(raw))
        clean_num = None
        if len(digits) == 11:
            if digits.startswith('7'): clean_num = digits
            elif digits.startswith('8'): clean_num = '7' + digits[1:]
        elif len(digits) == 10 and digits.startswith('9'):
            clean_num = '7' + digits
        if clean_num: candidates.append(clean_num)
    return list(set(candidates))

def process_checknumber_task(phone_list):
    if not phone_list: return set()
    valid_numbers_set = set()
    
    api_key = check_key.strip()
    user_id = check_user_id.strip()
    if not api_key or not user_id: st.error("Missing API Key/User ID"); return set()

    headers = {"X-API-Key": api_key, "User-Agent": "Mozilla/5.0"}
    my_proxy_str = get_proxy_config()
    req_proxies = {"http": my_proxy_str, "https": my_proxy_str} if my_proxy_str else None
    
    status_box = st.status("ğŸ“¡ Establishing Connection...", expanded=True)
    status_box.write(f"Uploading {len(phone_list)} numbers for verification...")
    
    # 1. Upload
    file_content = "\n".join(phone_list)
    files = {'file': ('input.txt', file_content, 'text/plain')}
    data_payload = {'user_id': user_id} 
    try:
        resp = requests.post(CONFIG["CN_BASE_URL"], headers=headers, files=files, data=data_payload, proxies=req_proxies, timeout=30, verify=False)
        if resp.status_code != 200:
            status_box.update(label="âŒ Upload Failed", state="error"); st.error(resp.text); return set()
        task_id = resp.json().get("task_id")
    except: status_box.update(label="âŒ Network Error", state="error"); return set()

    # 2. Poll
    status_url = f"{CONFIG['CN_BASE_URL']}/{task_id}"
    result_url = None
    for i in range(80):
        try:
            time.sleep(4)
            poll_resp = requests.get(status_url, headers=headers, params={'user_id': user_id}, proxies=req_proxies, timeout=30, verify=False)
            if poll_resp.status_code == 200:
                p_data = poll_resp.json()
                status = p_data.get("status")
                done = p_data.get("success", 0) + p_data.get("failure", 0)
                total = p_data.get("total", 1)
                status_box.write(f"Verifying... {done}/{total} (Status: {status})")
                if status in ["exported", "completed"]: result_url = p_data.get("result_url"); break
        except: pass
            
    if not result_url: status_box.update(label="âŒ Timeout", state="error"); return set()
        
    # 3. Download
    try:
        status_box.write("Analyzing report...")
        f_resp = requests.get(result_url, proxies=req_proxies, verify=False)
        if f_resp.status_code == 200:
            try: res_df = pd.read_excel(io.BytesIO(f_resp.content))
            except: res_df = pd.read_csv(io.BytesIO(f_resp.content))
            res_df.columns = [c.lower() for c in res_df.columns]
            for _, r in res_df.iterrows():
                ws = str(r.get('whatsapp') or r.get('status') or '').lower()
                num = str(r.get('number') or r.get('phone') or '')
                cn = re.sub(r'\D', '', num)
                if "yes" in ws or "valid" in ws: valid_numbers_set.add(cn)
            status_box.update(label=f"âœ… Verified: {len(valid_numbers_set)} active accounts", state="complete")
    except: status_box.update(label="âŒ Parse Error", state="error")

    return valid_numbers_set

def get_ai_message_premium(client, shop_name, shop_link, web_content):
    """
    v21.0 æ——èˆ° AI é€»è¾‘ï¼šç»“åˆç½‘é¡µå†…å®¹ + URL + åº—å
    """
    if pd.isna(shop_name): shop_name = "Seller"
    if pd.isna(shop_link): shop_link = "Ozon Store"
    
    # æ„å»ºä¿¡æ¯æº
    source_info = f"URL: {shop_link}"
    if web_content:
        source_info += f"\nScraped Page Content: {web_content}"
    
    prompt = f"""
    Role: Senior Business Development Director at "988 Group" (China).
    Target: Ozon Seller "{shop_name}".
    Source Info: 
    {source_info}
    
    Context:
    988 Group is a premier Supply Chain Partner offering:
    1. Direct Sourcing (Factory Pricing).
    2. Logistics & Customs Clearance to Russia (Door-to-Door).
    
    Task:
    1. Analyze the 'Source Info' to identify their EXACT product niche (e.g., Baby Strollers, Car DVRs, Pet Food).
    2. Create a hyper-personalized Russian WhatsApp message.
    
    Structure:
    - Opening: "Saw your [Specific Product] collection on Ozon..." (Be specific!)
    - Value: "We help top sellers source [Specific Product] directly from China factories + handle shipping to Moscow."
    - CTA: "Open to a quote?"
    
    Constraint: Native Russian. Professional yet conversational. <40 words.
    Output: Russian text only.
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7, 
            max_tokens=250
        )
        return response.choices[0].message.content.strip()
    except:
        return f"Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ, {shop_name}! ĞœÑ‹ 988 Group (ĞšĞ¸Ñ‚Ğ°Ğ¹). ĞŸĞ¾Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ñ Ğ·Ğ°ĞºÑƒĞ¿ĞºĞ¾Ğ¹ Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¾Ğ¹ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ². ĞĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¾?"

def make_wa_link(phone, text):
    return f"https://wa.me/{phone}?text={urllib.parse.quote(text)}"

# === ä¸»ç¨‹åºç•Œé¢ ===

# å¤´éƒ¨ Header
st.markdown("### ğŸš€ 988 Group AI-Driven Supply Chain")
st.markdown("Automated Sourcing & Logistics Lead Generation")
st.markdown("---")

uploaded_file = st.file_uploader("ğŸ“‚ Upload Lead List (Excel/CSV)", type=['xlsx', 'csv'])

if uploaded_file:
    try:
        if uploaded_file.name.endswith('.csv'): df = pd.read_csv(uploaded_file, header=None)
        else: df = pd.read_excel(uploaded_file, header=None)
        df = df.astype(str)
    except: st.stop()
        
    # é«˜çº§åˆ—é€‰æ‹©å™¨
    with st.container():
        st.info("ğŸ‘‡ Map your data columns for AI Context")
        c1, c2 = st.columns(2)
        with c1:
            shop_col_idx = st.selectbox("ğŸ·ï¸ Store Name Column", range(len(df.columns)), index=1 if len(df.columns)>1 else 0)
        with c2:
            link_col_idx = st.selectbox("ğŸ”— Store Link Column (Crucial for AI)", range(len(df.columns)), index=0)

    st.markdown("<br>", unsafe_allow_html=True)

    if st.button("ğŸš€ START AI ENGINE", type="primary"):
        
        # 1. é‰´æƒ
        my_proxy_str = get_proxy_config()
        if not openai_key: st.error("âŒ OpenAI Key Missing"); st.stop()

        client = None
        if my_proxy_str:
            try:
                try: http_client = httpx.Client(proxy=my_proxy_str, verify=False)
                except: http_client = httpx.Client(proxies=my_proxy_str, verify=False)
                client = OpenAI(api_key=openai_key, http_client=http_client)
            except: st.error("Proxy Error"); st.stop()
        else:
            client = OpenAI(api_key=openai_key)

        # 2. æå–
        all_raw_phones = set()
        phone_to_rows = {}
        
        # è¿›åº¦æ˜¾ç¤º
        progress_text = st.empty()
        progress_bar = st.progress(0)
        
        for i, row in df.iterrows():
            extracted = extract_all_numbers(row)
            for p in extracted:
                all_raw_phones.add(p)
                if p not in phone_to_rows: phone_to_rows[p] = []
                phone_to_rows[p].append(i)
            progress_bar.progress((i+1)/len(df))
            
        if not all_raw_phones: st.error("No numbers found."); st.stop()

        # 3. éªŒå·
        valid_phones_set = process_checknumber_task(list(all_raw_phones))
        
        # 4. AI ç”Ÿæˆ (å«çˆ¬è™«)
        if valid_phones_set:
            # æ•°æ®çœ‹æ¿
            st.markdown("---")
            kpi1, kpi2, kpi3 = st.columns(3)
            kpi1.metric("Raw Numbers", len(all_raw_phones))
            kpi2.metric("Verified WA", len(valid_phones_set))
            kpi3.metric("Conversion Rate", f"{len(valid_phones_set)/len(all_raw_phones)*100:.1f}%")
            
            st.success("ğŸ§  AI is analyzing store content & writing copy...")
            final_results = []
            
            valid_rows_indices = set()
            for p in valid_phones_set:
                for r in phone_to_rows.get(p, []): valid_rows_indices.add(r)
            sorted_indices = sorted(list(valid_rows_indices))
            
            ai_bar = st.progress(0)
            
            for idx_step, row_idx in enumerate(sorted_indices):
                row = df.iloc[row_idx]
                row_phones = extract_all_numbers(row)
                row_valid = [p for p in row_phones if p in valid_phones_set]
                
                if row_valid:
                    shop_name = row[shop_col_idx]
                    shop_link = row[link_col_idx]
                    
                    # === å…³é”®æ­¥éª¤ï¼šå°è¯•çˆ¬å–å†…å®¹ ===
                    web_content = extract_web_content(shop_link)
                    
                    # === AI ç”Ÿæˆ ===
                    ai_msg = get_ai_message_premium(client, shop_name, shop_link, web_content)
                    
                    links = [make_wa_link(p, ai_msg) for p in row_valid]
                    final_results.append({
                        "Shop Name": shop_name,
                        "Link": shop_link,
                        "AI Context": "Scraped" if web_content else "URL Only",
                        "Phone": ", ".join(row_valid),
                        "Personalized Message": ai_msg,
                        "Direct Link": " | ".join(links)
                    })
                ai_bar.progress((idx_step+1)/len(sorted_indices))
            
            res_df = pd.DataFrame(final_results)
            
            st.subheader("ğŸ¯ Qualified Leads")
            for _, item in res_df.head(50).iterrows():
                with st.expander(f"ğŸ¢ {item['Shop Name']} ({item['AI Context']})"):
                    st.write(f"**Generated:** {item['Personalized Message']}")
                    st.caption(f"Source: {item['Link']}")
                    for l in item['Direct Link'].split(" | "): 
                        st.link_button("ğŸ“² Send via WhatsApp", l)
            
            csv = res_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ Download Final Report", csv, "988_premium_leads.csv", "text/csv")
        else:
            st.warning("No valid WhatsApp numbers found.")
